{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторна робота № 2\n",
        "### Тема: \"Наївний баєсів класифікатор для аналізу тональності текстів\""
      ],
      "metadata": {
        "id": "m_Hp9-V3Pjab"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvdEVl1ZPPqG"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import stopwords, twitter_samples\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ЗАВДАННЯ 1: Завантаження та попередня обробка"
      ],
      "metadata": {
        "id": "a33s0LqwP7wU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tweet(tweet):\n",
        "    \"\"\"\n",
        "    Обробляє твіт: токенізація, видалення стоп-слів, стемінг.\n",
        "    (Функція надана в описі лабораторної)\n",
        "    \"\"\"\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "\n",
        "    # Видалення $GE, RT, посилань\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
        "    # Видалення хештегів (#)\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "\n",
        "    # Токенізація\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and  # видалення стоп-слів\n",
        "            word not in string.punctuation):   # видалення пунктуації\n",
        "            stem_word = stemmer.stem(word)  # стемінг\n",
        "            tweets_clean.append(stem_word)\n",
        "\n",
        "    return tweets_clean"
      ],
      "metadata": {
        "id": "K-qZJS2lP47W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ЗАВДАННЯ 2: Побудова словника частотності"
      ],
      "metadata": {
        "id": "h6pKAfhsQdTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tweets(result, tweets, ys):\n",
        "    \"\"\"\n",
        "    Будує словник частот freqs[(word, label)] = count.\n",
        "    (Функція надана в описі лабораторної)\n",
        "    \"\"\"\n",
        "    # Переконуємось, що ys - це звичайний список\n",
        "    if isinstance(ys, np.ndarray):\n",
        "        yslist = np.squeeze(ys).tolist()\n",
        "    else:\n",
        "        yslist = ys\n",
        "\n",
        "    for y, tweet in zip(yslist, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            pair = (word, y)\n",
        "            result[pair] = result.get(pair, 0) + 1\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "KwrJKlR_Qdjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ЗАВДАННЯ 3 & 4: Обчислення Log Prior та Log Likelihood"
      ],
      "metadata": {
        "id": "eYsy7Dq2Q1aN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_naive_bayes(freqs, train_y):\n",
        "    \"\"\"\n",
        "    Навчає модель: обчислює logprior та loglikelihood.\n",
        "    (Функція надана в описі лабораторної, з виправленням міток)\n",
        "    \"\"\"\n",
        "    loglikelihood = {}\n",
        "    logprior = 0\n",
        "\n",
        "    # Отримуємо унікальні слова (словник V)\n",
        "    vocab = set([pair[0] for pair in freqs.keys()])\n",
        "    V = len(vocab)\n",
        "\n",
        "    # N_pos, N_neg - загальна кількість слів у кожному класі\n",
        "    N_pos = N_neg = 0\n",
        "    for pair, count in freqs.items():\n",
        "        # pair[1] - це мітка (1.0 або 0.0)\n",
        "        if pair[1] > 0: # Позитивний (1.0)\n",
        "            N_pos += count\n",
        "        else: # Негативний (0.0)\n",
        "            N_neg += count\n",
        "\n",
        "    # D - загальна к-сть документів (твітів)\n",
        "    D = len(train_y)\n",
        "    # D_pos, D_neg - к-сть позитивних/негативних документів\n",
        "    D_pos = np.sum(train_y) # Сума всіх '1'\n",
        "    D_neg = D - D_pos\n",
        "\n",
        "    # ЗАВДАННЯ 3: Обчислення Log Prior\n",
        "    logprior = np.log(D_pos) - np.log(D_neg)\n",
        "\n",
        "    # ЗАВДАННЯ 4: Обчислення Log Likelihood\n",
        "    for word in vocab:\n",
        "        # Отримуємо частоти слів (з уникненням KeyError)\n",
        "        freq_pos = freqs.get((word, 1.0), 0)\n",
        "        freq_neg = freqs.get((word, 0.0), 0)\n",
        "\n",
        "        # Обчислюємо ймовірності P(W|Pos) та P(W|Neg) зі згладжуванням Лапласа (+1)\n",
        "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
        "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
        "\n",
        "        loglikelihood[word] = np.log(p_w_pos / p_w_neg)\n",
        "\n",
        "    return logprior, loglikelihood"
      ],
      "metadata": {
        "id": "DAWiBtO2Q1is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ЗАВДАННЯ 5: Реалізація функції класифікатора"
      ],
      "metadata": {
        "id": "uQuA0f_sRGNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_bayes_predict(tweet, logprior, loglikelihood):\n",
        "    \"\"\"\n",
        "    Прогнозує тональність твіту.\n",
        "    (Функція надана в описі лабораторної)\n",
        "    \"\"\"\n",
        "    word_l = process_tweet(tweet)\n",
        "\n",
        "    # Починаємо з апріорної ймовірності\n",
        "    p = logprior\n",
        "\n",
        "    for word in word_l:\n",
        "        if word in loglikelihood:\n",
        "            # Додаємо логарифм правдоподібності для цього слова\n",
        "            p += loglikelihood[word]\n",
        "\n",
        "    # Якщо p > 0, твіт позитивний, інакше - негативний\n",
        "    return p"
      ],
      "metadata": {
        "id": "9jZOKOKeRJxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ЗАВДАННЯ 6: Оцінка точності"
      ],
      "metadata": {
        "id": "RVTsPUoURVEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
        "    \"\"\"\n",
        "    Оцінює точність класифікатора на тестовій вибірці.\n",
        "    (Функція надана в описі лабораторної, з виправленням типів)\n",
        "    \"\"\"\n",
        "    y_hats = [] # Список наших прогнозів\n",
        "\n",
        "    for tweet in test_x:\n",
        "        # Отримуємо прогноз (score)\n",
        "        p = naive_bayes_predict(tweet, logprior, loglikelihood)\n",
        "\n",
        "        # Якщо score > 0, мітка 1.0 (Pos), інакше 0.0 (Neg)\n",
        "        if p > 0:\n",
        "            y_hat_i = 1.0\n",
        "        else:\n",
        "            y_hat_i = 0.0\n",
        "        y_hats.append(y_hat_i)\n",
        "\n",
        "    # Порівнюємо прогнози (y_hats) з реальними мітками (test_y)\n",
        "    # np.mean(y_hats == test_y) - це елегантний спосіб порахувати точність\n",
        "    error = np.mean(np.absolute(np.array(y_hats) - test_y))\n",
        "    accuracy = 1 - error\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "GkwmqBcjRYyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ЗАВДАННЯ 7: Аналіз слів"
      ],
      "metadata": {
        "id": "IYd1AmQiRb2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lookup(freqs, word, label):\n",
        "    \"\"\"(Функція надана в описі лабораторної)\"\"\"\n",
        "    n = 0\n",
        "    pair = (word, label)\n",
        "    if (pair in freqs):\n",
        "        n = freqs[pair]\n",
        "    return n\n",
        "\n",
        "def get_ratio(freqs, word):\n",
        "    \"\"\"(Функція надана в описі лабораторної, з виправленням міток)\"\"\"\n",
        "    pos_neg_ratio = {'positive': 0, 'negative': 0, 'ratio': 0.0}\n",
        "    pos_neg_ratio['positive'] = lookup(freqs, word, 1.0) # Використовуємо 1.0\n",
        "    pos_neg_ratio['negative'] = lookup(freqs, word, 0.0) # Використовуємо 0.0\n",
        "\n",
        "    pos_neg_ratio['ratio'] = (pos_neg_ratio['positive'] + 1) / (pos_neg_ratio['negative'] + 1)\n",
        "    return pos_neg_ratio\n",
        "\n",
        "def get_words_by_threshold(freqs, label, threshold):\n",
        "    \"\"\"(Функція надана в описі лабораторної)\"\"\"\n",
        "    word_list = {}\n",
        "    for key in freqs.keys():\n",
        "        word, _ = key\n",
        "        pos_neg_ratio = get_ratio(freqs, word)\n",
        "\n",
        "        if label == 1 and pos_neg_ratio['ratio'] >= threshold:\n",
        "            word_list[word] = pos_neg_ratio\n",
        "        elif label == 0 and pos_neg_ratio['ratio'] <= threshold:\n",
        "            word_list[word] = pos_neg_ratio\n",
        "\n",
        "    return word_list"
      ],
      "metadata": {
        "id": "EHlMfE6NRfK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ГОЛОВНИЙ БЛОК ВИКОНАННЯ"
      ],
      "metadata": {
        "id": "MeL8-rkeRlBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # 1. Завантаження NLTK даних\n",
        "    nltk.download('twitter_samples', quiet=True)\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "    nltk.download('punkt', quiet=True) # Потрібен для TweetTokenizer\n",
        "\n",
        "    # 2. (Завдання 1) Завантаження та розділення корпусу\n",
        "    print(\"Завантаження та розділення даних twitter_samples...\")\n",
        "    all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "    all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "    train_pos = all_positive_tweets[:4000]\n",
        "    test_pos = all_positive_tweets[4000:]\n",
        "    train_neg = all_negative_tweets[:4000]\n",
        "    test_neg = all_negative_tweets[4000:]\n",
        "\n",
        "    train_x = train_pos + train_neg\n",
        "    test_x = test_pos + test_neg\n",
        "\n",
        "    # Створюємо мітки: 1.0 для позитивних, 0.0 для негативних (як у build_freqs)\n",
        "    train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
        "    test_y = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))\n",
        "    print(f\"Тренувальна вибірка: {len(train_x)} твітів\")\n",
        "    print(f\"Тестова вибірка: {len(test_x)} твітів\")\n",
        "\n",
        "    # 3. (Завдання 2) Побудова словника частотності\n",
        "    print(\"\\nПобудова словника частот...\")\n",
        "    # Передаємо мітки train_y (1.0/0.0)\n",
        "    freqs = count_tweets({}, train_x, train_y)\n",
        "    print(f\"Словник частот побудовано. {len(freqs)} унікальних пар.\")\n",
        "\n",
        "    # 4. (Завдання 3 & 4) Навчання моделі\n",
        "    print(\"\\nНавчання моделі (обчислення logprior та loglikelihood)...\")\n",
        "    logprior, loglikelihood = train_naive_bayes(freqs, train_y)\n",
        "    print(f\"Навчання завершено. LogPrior = {logprior:.4f}\")\n",
        "\n",
        "    # 5. (Завдання 6) Оцінка точності\n",
        "    print(\"\\n--- Завдання 6: Оцінка точності ---\")\n",
        "    accuracy = test_naive_bayes(test_x, test_y, logprior, loglikelihood)\n",
        "    print(f\"Точність наївного баєсового класифікатора: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # 6. (Завдання 7) Аналіз слів\n",
        "    print(\"\\n--- Завдання 7: Аналіз слів ---\")\n",
        "    print(\"Найбільш позитивні слова (ratio >= 10):\")\n",
        "    pos_words = get_words_by_threshold(freqs, label=1, threshold=10)\n",
        "    for word, ratio in sorted(pos_words.items(), key=lambda x: x[1]['ratio'], reverse=True)[:10]:\n",
        "        print(f\"  {word}: {ratio['ratio']:.2f} (Pos: {ratio['positive']}, Neg: {ratio['negative']})\")\n",
        "\n",
        "    print(\"\\nНайбільш негативні слова (ratio <= 0.1):\")\n",
        "    neg_words = get_words_by_threshold(freqs, label=0, threshold=0.1)\n",
        "    for word, ratio in sorted(neg_words.items(), key=lambda x: x[1]['ratio'])[:10]:\n",
        "        print(f\"  {word}: {ratio['ratio']:.2f} (Pos: {ratio['positive']}, Neg: {ratio['negative']})\")\n",
        "\n",
        "    # 7. (Завдання 8) Аналіз помилок\n",
        "    print(\"\\n--- Завдання 8: Аналіз помилок ---\")\n",
        "    print('True\\tPred\\tTweet (перші 20 помилок)')\n",
        "    print('-------------------------------------')\n",
        "    errors_found = 0\n",
        "    for x, y in zip(test_x, test_y):\n",
        "        if errors_found >= 20: # Обмежимо вивід\n",
        "            break\n",
        "\n",
        "        y_hat_score = naive_bayes_predict(x, logprior, loglikelihood)\n",
        "        y_hat = 1.0 if y_hat_score > 0 else 0.0\n",
        "\n",
        "        if y != y_hat:\n",
        "            errors_found += 1\n",
        "            # .encode('ascii', 'ignore') - щоб уникнути помилок виводу\n",
        "            print(f'{y}\\t{y_hat}\\t{x.encode(\"ascii\", \"ignore\")}')\n",
        "\n",
        "    # 8. (Завдання 9) Тестування на власних твітах\n",
        "    print(\"\\n--- Завдання 9: Тест на власному твіті ---\")\n",
        "\n",
        "    my_tweet_1 = 'I am happy because I am learning :)'\n",
        "    p1 = naive_bayes_predict(my_tweet_1, logprior, loglikelihood)\n",
        "    print(f\"Твіт: '{my_tweet_1}'\")\n",
        "    print(f\"  Score: {p1:.4f} -> Прогноз: {'Позитивний' if p1 > 0 else 'Негативний'}\")\n",
        "\n",
        "    my_tweet_2 = 'This is a terrible and awful experience. I hate it.'\n",
        "    p2 = naive_bayes_predict(my_tweet_2, logprior, loglikelihood)\n",
        "    print(f\"\\nТвіт: '{my_tweet_2}'\")\n",
        "    print(f\"  Score: {p2:.4f} -> Прогноз: {'Позитивний' if p2 > 0 else 'Негативний'}\")\n",
        "\n",
        "    my_tweet_3 = \"This movie was not bad, actually. I kind of liked it.\"\n",
        "    p3 = naive_bayes_predict(my_tweet_3, logprior, loglikelihood)\n",
        "    print(f\"\\nТвіт (складний): '{my_tweet_3}'\")\n",
        "    print(f\"  Score: {p3:.4f} -> Прогноз: {'Позитивний' if p3 > 0 else 'Негативний'}\")\n",
        "\n",
        "    # 9. (Завдання 10) Збереження моделі для GitHub\n",
        "    print(\"\\n--- Завдання 10: Збереження моделі ---\")\n",
        "    model_data = {\n",
        "        'logprior': logprior,\n",
        "        'loglikelihood': loglikelihood\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with open('naive_bayes_model.json', 'w', encoding='utf-8') as f:\n",
        "            json.dump(model_data, f, indent=4)\n",
        "        print(\"Модель (logprior та loglikelihood) успішно збережено у 'naive_bayes_model.json'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Помилка збереження моделі: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEYdY16eRnO6",
        "outputId": "0c714052-b70b-43bd-d68d-4b4098377b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Завантаження та розділення даних twitter_samples...\n",
            "Тренувальна вибірка: 8000 твітів\n",
            "Тестова вибірка: 2000 твітів\n",
            "\n",
            "Побудова словника частот...\n",
            "Словник частот побудовано. 11397 унікальних пар.\n",
            "\n",
            "Навчання моделі (обчислення logprior та loglikelihood)...\n",
            "Навчання завершено. LogPrior = 0.0000\n",
            "\n",
            "--- Завдання 6: Оцінка точності ---\n",
            "Точність наївного баєсового класифікатора: 99.55%\n",
            "\n",
            "--- Завдання 7: Аналіз слів ---\n",
            "Найбільш позитивні слова (ratio >= 10):\n",
            "  :): 987.00 (Pos: 2960, Neg: 2)\n",
            "  :-): 553.00 (Pos: 552, Neg: 0)\n",
            "  :d: 524.00 (Pos: 523, Neg: 0)\n",
            "  :p: 106.00 (Pos: 105, Neg: 0)\n",
            "  stat: 52.00 (Pos: 51, Neg: 0)\n",
            "  bam: 45.00 (Pos: 44, Neg: 0)\n",
            "  warsaw: 45.00 (Pos: 44, Neg: 0)\n",
            "  blog: 28.00 (Pos: 27, Neg: 0)\n",
            "  fback: 27.00 (Pos: 26, Neg: 0)\n",
            "  followfriday: 24.00 (Pos: 23, Neg: 0)\n",
            "\n",
            "Найбільш негативні слова (ratio <= 0.1):\n",
            "  :(: 0.00 (Pos: 1, Neg: 3675)\n",
            "  :-(: 0.00 (Pos: 0, Neg: 386)\n",
            "  ♛: 0.00 (Pos: 0, Neg: 210)\n",
            "  》: 0.00 (Pos: 0, Neg: 210)\n",
            "  >:(: 0.02 (Pos: 0, Neg: 43)\n",
            "  beli̇ev: 0.03 (Pos: 0, Neg: 35)\n",
            "  wi̇ll: 0.03 (Pos: 0, Neg: 35)\n",
            "  justi̇n: 0.03 (Pos: 0, Neg: 35)\n",
            "  ｓｅｅ: 0.03 (Pos: 0, Neg: 35)\n",
            "  ｍｅ: 0.03 (Pos: 0, Neg: 35)\n",
            "\n",
            "--- Завдання 8: Аналіз помилок ---\n",
            "True\tPred\tTweet (перші 20 помилок)\n",
            "-------------------------------------\n",
            "1.0\t0.0\tb'@jaredNOTsubway @iluvmariah @Bravotv Then that truly is a LATERAL move! Now, we all know the Queen Bee is UPWARD BOUND : ) #MovingOnUp'\n",
            "1.0\t0.0\tb'A new report talks about how we burn more calories in the cold, because we work harder to warm up. Feel any better about the weather? :p'\n",
            "1.0\t0.0\tb\"Harry and niall and -94 (when harry was born) ik it's stupid and i wanna change it :D https://t.co/gHAt8ZDAfF\"\n",
            "1.0\t0.0\tb'off to the park to get some sunlight : )'\n",
            "1.0\t0.0\tb'@msarosh Uff Itna Miss karhy thy ap :p'\n",
            "0.0\t1.0\tb'@rcdlccom hello, any info about possible interest in Jonathas ?? He is close to join Betis :( greatings'\n",
            "0.0\t1.0\tb'@phenomyoutube u probs had more fun with david than me : ('\n",
            "0.0\t1.0\tb'pats jay : ('\n",
            "0.0\t1.0\tb'Sr. Financial Analyst - Expedia, Inc.: (#Bellevue, WA) http://t.co/ktknMhvwCI #Finance #ExpediaJobs #Job #Jobs #Hiring'\n",
            "\n",
            "--- Завдання 9: Тест на власному твіті ---\n",
            "Твіт: 'I am happy because I am learning :)'\n",
            "  Score: 9.5605 -> Прогноз: Позитивний\n",
            "\n",
            "Твіт: 'This is a terrible and awful experience. I hate it.'\n",
            "  Score: -4.4578 -> Прогноз: Негативний\n",
            "\n",
            "Твіт (складний): 'This movie was not bad, actually. I kind of liked it.'\n",
            "  Score: -0.9166 -> Прогноз: Негативний\n",
            "\n",
            "--- Завдання 10: Збереження моделі ---\n",
            "Модель (logprior та loglikelihood) успішно збережено у 'naive_bayes_model.json'\n"
          ]
        }
      ]
    }
  ]
}